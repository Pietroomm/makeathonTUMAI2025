{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d63f31-141e-4064-90be-ab91a75ac0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "#!pip install opencv-python\n",
    "#!pip install pyproj\n",
    "\n",
    "# Helper: fit a 2D line via PCA\n",
    "def fit_line_2d(pts: np.ndarray):\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(pts)\n",
    "    direction = pca.components_[0]\n",
    "    centroid = pca.mean_\n",
    "    direction /= np.linalg.norm(direction)\n",
    "    return centroid, direction\n",
    "\n",
    "# Helper: angle between a direction vector and the image horizontal axis\n",
    "def angle_to_horizontal(direction: np.ndarray):\n",
    "    horiz = np.array([1.0, 0.0])\n",
    "    cosang = np.clip(np.dot(direction, horiz), -1.0, 1.0)\n",
    "    return np.degrees(np.arccos(abs(cosang)))\n",
    "\n",
    "# Main pipeline function\n",
    "def process_images(df: pd.DataFrame,\n",
    "                   image_width_px: int,\n",
    "                   image_height_px: int,\n",
    "                   barcode_vis_thresh: float = 0.7):\n",
    "    \"\"\"\n",
    "    Processes a DataFrame of detected objects to produce, per left-to-right rank across images,\n",
    "    the pallet points and corresponding camera GPS.\n",
    "\n",
    "    Parameters:\n",
    "      df: pandas.DataFrame with columns:\n",
    "        ['image', 'class', 'x1', 'x2', 'y1', 'y2', 'latitude', 'longitude', 'altitude']\n",
    "        where 'class' is either 'barcode' or 'pallets'.\n",
    "      image_width_px: width of the image in pixels (for optical center X coordinate).\n",
    "      image_height_px: height of the image in pixels (for optical center Y coordinate).\n",
    "      barcode_vis_thresh: fraction of the maximum barcodes (per any image) required to process an image.\n",
    "\n",
    "    Returns:\n",
    "      final_list: list of dicts, one per left-to-right rank index.\n",
    "        Each dict maps image name to a sub-dict with:\n",
    "          - '<ordinal> point': (x, y) pixel coordinate of the pallet point.\n",
    "          - 'lat', 'lon', 'alt': camera position for that image.\n",
    "    \"\"\"\n",
    "    # 1) Determine threshold count from maximum barcodes in any image\n",
    "    bc_counts = df[df['class']=='barcode'].groupby('image').size()\n",
    "    max_barcodes = int(bc_counts.max()) if not bc_counts.empty else 0\n",
    "    thresh_count = max_barcodes * barcode_vis_thresh\n",
    "\n",
    "    # Precompute optical center of the image\n",
    "    optical_center = np.array([image_width_px / 2.0, image_height_px / 2.0], dtype=float)\n",
    "\n",
    "    # 2) Fit and select pallet points per image\n",
    "    sorted_pts = {}    # maps image -> list of sorted (x,y) points\n",
    "    cam_meta   = {}   # maps image -> {'lat', 'lon', 'alt'}\n",
    "\n",
    "    for img, grp in df.groupby('image'):\n",
    "        # a) Check barcode visibility\n",
    "        count_barcode = (grp['class']=='barcode').sum()\n",
    "        if count_barcode < thresh_count:\n",
    "            continue\n",
    "\n",
    "        # b) Record camera GPS metadata\n",
    "        lat = grp['latitude'].iloc[0]\n",
    "        lon = grp['longitude'].iloc[0]\n",
    "        alt = grp['altitude'].iloc[0]\n",
    "        cam_meta[img] = {'lat': lat, 'lon': lon, 'alt': alt}\n",
    "\n",
    "        # c) Extract pallet coordinates\n",
    "        pal = grp[grp['class']=='pallets']\n",
    "        if pal.shape[0] < 2:\n",
    "            continue\n",
    "        pts1 = pal[['x1','y1']].to_numpy()\n",
    "        pts2 = pal[['x2','y2']].to_numpy()\n",
    "\n",
    "        # d) Fit two lines and require horizontal orientation\n",
    "        _, dir1 = fit_line_2d(pts1)\n",
    "        if angle_to_horizontal(dir1) >= 45.0:\n",
    "            continue\n",
    "        # (optional) could check parallelism with second line\n",
    "\n",
    "        # e) Choose the line closer to the optical center\n",
    "        d1 = np.linalg.norm(pts1 - optical_center, axis=1).mean()\n",
    "        d2 = np.linalg.norm(pts2 - optical_center, axis=1).mean()\n",
    "        chosen = pts1 if d1 < d2 else pts2\n",
    "\n",
    "        # f) Sort chosen points left-to-right\n",
    "        order = np.argsort(chosen[:,0])\n",
    "        sorted_pts[img] = chosen[order].tolist()\n",
    "\n",
    "    # 3) Build final_list by left-to-right rank\n",
    "    final_list = []\n",
    "    if sorted_pts:\n",
    "        max_rank = max(len(pts) for pts in sorted_pts.values())\n",
    "        for rank in range(max_rank):\n",
    "            rank_entry = {}\n",
    "            for img, pts in sorted_pts.items():\n",
    "                if rank >= len(pts):\n",
    "                    continue\n",
    "                x, y = pts[rank]\n",
    "\n",
    "                # Assemble entry using stored cam_meta\n",
    "                meta = cam_meta[img]\n",
    "                rank_entry[img] = {\n",
    "                     \"point\": (x, y),\n",
    "                    'lat': meta['lat'],\n",
    "                    'lon': meta['lon'],\n",
    "                    'alt': meta['alt']\n",
    "                }\n",
    "            final_list.append(rank_entry)\n",
    "\n",
    "    return final_list\n",
    "\n",
    "import nbimporter\n",
    "from add_camera_position import get_df_with_camera_position\n",
    "df = get_df_with_camera_position()\n",
    "\n",
    "result = process_images(df, image_width_px=4032, image_height_px=3024)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pyproj import Transformer\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def get_3d(data):\n",
    "    \"\"\"\n",
    "    data: dict mapping image_filename -> {\n",
    "      'leftmost point': (x_px, y_px),\n",
    "      'lat': float, 'lon': float, 'alt': float\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Camera intrinsics (DJI M4TD wide) – unchanged\n",
    "    sensor_width_mm  = 7.6\n",
    "    sensor_height_mm = 5.7\n",
    "    focal_length_mm  = 7.0\n",
    "    image_width_px   = 1280\n",
    "    image_height_px  = 720\n",
    "\n",
    "    fx = (focal_length_mm / sensor_width_mm)  * image_width_px\n",
    "    fy = (focal_length_mm / sensor_height_mm) * image_height_px\n",
    "    cx, cy = image_width_px/2, image_height_px/2\n",
    "\n",
    "    K = np.array([[fx,  0, cx],\n",
    "                  [ 0, fy, cy],\n",
    "                  [ 0,  0,  1]])\n",
    "\n",
    "    # 2) CRS transformers\n",
    "    to_ecef   = Transformer.from_crs(\"epsg:4326\",\"epsg:4978\",always_xy=True)\n",
    "    from_ecef = Transformer.from_crs(\"epsg:4978\",\"epsg:4326\",always_xy=True)\n",
    "\n",
    "    # 3) Nadir rotation\n",
    "    rot_nadir = R.from_euler('xyz', [0, -90, 0], degrees=True).as_matrix()\n",
    "\n",
    "    # 4) Build projection matrices\n",
    "    P_list = []\n",
    "    for img_name in data:\n",
    "        values= data[img_name]\n",
    "        Cx, Cy, Cz = to_ecef.transform(values[\"lon\"], values[\"lat\"], values[\"alt\"])\n",
    "        C = np.array([[Cx],[Cy],[Cz]])\n",
    "        Rt = np.hstack((rot_nadir, -rot_nadir @ C))\n",
    "        P_list.append(K @ Rt)\n",
    "\n",
    "    # 5) Collect 2D points\n",
    "    pts = np.array([data[img][\"point\"] for img in data], dtype=float)\n",
    "    if pts.shape[0] < 2:\n",
    "        raise ValueError(\"Need at least two cameras/points to triangulate\")\n",
    "\n",
    "    p1 = pts[0].reshape(2,1)\n",
    "    p2 = pts[1].reshape(2,1)\n",
    "\n",
    "    # 6) Triangulate\n",
    "    Xh = cv2.triangulatePoints(P_list[0], P_list[1], p1, p2)\n",
    "\n",
    "    # 7) From homogeneous to ECEF\n",
    "    X_ecef = (Xh[:3] / Xh[3]).flatten()\n",
    "\n",
    "    # 8) Back to GPS\n",
    "    lon, lat, alt = from_ecef.transform(*X_ecef)\n",
    "\n",
    "    print(f\"Triangulated GPS coordinates: lat={lat:.6f}, lon={lon:.6f}, alt≈{alt:.2f} m\")\n",
    "    return lon, lat, alt\n",
    "\n",
    "\n",
    "points_3d = []\n",
    "for coord in result:\n",
    "    print(coord)\n",
    "    \n",
    "    points_3d.append(get_3d(coord))\n",
    "\n",
    "print(\"FINAL\", points_3d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cde98a-0475-4756-a005-bd8864f27b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9904e-fe88-4351-beab-697c661bf83e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
